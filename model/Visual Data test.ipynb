{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54232e76-5223-458c-a3f2-28462acd8230",
   "metadata": {},
   "source": [
    "# Feature visualisation\n",
    "Feature visualisation is a technique to pinpoint image positions indicative of neuron activations. These can be across entier layers, channels or individual neurons.\n",
    "Feature visualisation is here used to gauge the expressiveness of the features in the training image of off the shelve models. If adequate no finetunine is currently necessary and one can procede with the next stage which is a time difference based self-supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ff81a-38df-471a-8f8e-28b55d68791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients, NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "\n",
    "input_img = dataset[8][0][None,:] #transform_normalize(transformed_img).unsqueeze(0)\n",
    "transformed_img = un_norm(input_img)\n",
    "model.train()\n",
    "model_raw.train()\n",
    "#model = torchvision.models.mobilenet_v3_large(weights=\"DEFAULT\")\n",
    "output = model(input_img)\n",
    "output = F.softmax(output, dim=1)\n",
    "prediction_score, pred_label_idx = torch.unsqueeze(output[0][1], 0)[None,:], torch.tensor([[1]], dtype=torch.long)#torch.topk(output, 1)\n",
    "# Initialize the attribution algorithm with the model\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "\n",
    "# Ask the algorithm to attribute our output target to\n",
    "#attributions_ig = integrated_gradients.attribute(input_img, target=pred_label_idx, n_steps=21)\n",
    "# Show the original image for comparison\n",
    "#_ = viz.visualize_image_attr(None, np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "#                      method=\"original_image\", title=\"Original Image\")\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom red',\n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#0000ff'),\n",
    "                                                  (1, '#0000ff')], N=256)\n",
    "#_ = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "#                             np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "#                             method='heat_map',\n",
    "#                             cmap=default_cmap,\n",
    "#                             show_colorbar=True,\n",
    "#                             sign='positive',\n",
    "#                             title='Integrated Gradients')\n",
    "noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "attributions_ig_nt = noise_tunnel.attribute(input_img, nt_samples=7, nt_type='smoothgrad_sq', target=pred_label_idx, n_steps=22, nt_samples_batch_size=2)\n",
    "\n",
    "#_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "#                                      np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "#                                      [\"original_image\", \"heat_map\"],\n",
    "#                                      [\"all\", \"positive\"],\n",
    "#                                      cmap=default_cmap,\n",
    "#                                      show_colorbar=True ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe4c19-6f06-4aa0-9e6c-4fb3eca76fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"IG of Train\")\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom red',\n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#00ff04'),\n",
    "                                                  (1, '#00ff04')], N=256)\n",
    "fig, ax = viz.visualize_image_attr(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      original_image=np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      sign='positive',\n",
    "                                     method='blended_heat_map',\n",
    "                                      #[\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)\n",
    "fig.savefig('train_hybridhead_locked.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8254a0-7fa3-42f1-85e8-8786bcd86edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.meta['categories'][466]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
